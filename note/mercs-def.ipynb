{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERCS Exp Def\n",
    "\n",
    "MERCS Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arff\n",
    "import os\n",
    "import numpy as np\n",
    "import aaai20\n",
    "import PxW\n",
    "\n",
    "from os.path import dirname\n",
    "\n",
    "from aaai20.io import filename_dataset, filename_query\n",
    "from aaai20.exp import collect_results\n",
    "from aaai20.wrangling import arff_to_df\n",
    "from aaai20.exp import collect_results, process_outcomes, save_outcome\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from modulo.utils.encoding import query_to_code, code_to_query, encode_attribute\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mercs.core import MERCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_to_ok_df(filename, return_qry=True, return_nominal=False):\n",
    "    \"\"\"\n",
    "    Convenience function. Preprocess so its ready for sklearn.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = arff_to_df(filename, return_af=False, encode_nominal=True)\n",
    "    \n",
    "    if return_qry:\n",
    "        qry = qry_from_df(df)\n",
    "\n",
    "    \"\"\"\n",
    "    df_nominal = df.select_dtypes(exclude=['number'])\n",
    "    df_nominal = df_nominal.apply(LabelEncoder().fit_transform)\n",
    "    df[df_nominal.columns] = df_nominal\n",
    "    \"\"\"\n",
    "    \n",
    "    nominal = np.where(df.dtypes==int)[0].tolist()\n",
    "    \n",
    "    c1 = return_qry\n",
    "    c2 = return_nominal\n",
    "    \n",
    "    if c1 and c2:\n",
    "        return df, qry, nominal\n",
    "    elif c1 and not c2:\n",
    "        return df, qry\n",
    "    elif not c1 and c2:\n",
    "        return df, nominal\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "def qry_from_df(df):\n",
    "    qry = np.zeros(len(df.columns), dtype=int)\n",
    "    miss_ids = df.columns[df.isna().any()].tolist()\n",
    "    targ_ids = df.columns[-1]\n",
    "    \n",
    "    qry[miss_ids] = -1\n",
    "    qry[targ_ids] = 1\n",
    "    return qry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_mercs(dataset,\n",
    "              target_idx=-1,\n",
    "              max_depth=8,\n",
    "              min_samples_leaf=10,\n",
    "              selection_algorithm=\"base\",):\n",
    "    # Preprocess\n",
    "    fn_train = filename_dataset(dataset, step=1, suffix='train')\n",
    "\n",
    "    df, nominal = fn_to_ok_df(fn_train, return_qry=False, return_nominal=True)\n",
    "    train = df.values\n",
    "    target_id = list(range(df.shape[1]))[target_idx] # Assumption: Last attribute is target\n",
    "\n",
    "    nominal_ids = set(list(nominal) + [target_id])\n",
    "\n",
    "    # Train\n",
    "    clf = MERCS()\n",
    "    clf.fit(df,\n",
    "            ind_max_depth=max_depth,\n",
    "            ind_min_samples_leaf=min_samples_leaf,\n",
    "            sel_algo=selection_algorithm,)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mercs(dataset,\n",
    "                  classifier,\n",
    "                  target_idx=-1,\n",
    "                  prediction_algorithm='mi',\n",
    "                  prediction_iterations=0.1,\n",
    "                  prediction_parameter=0.95):\n",
    "    result = []\n",
    "    \n",
    "    # Load queries\n",
    "    fn_qry = filename_query(dataset, suffix=\"default\")\n",
    "    q_codes = np.load(fn_qry)\n",
    "    \n",
    "    \n",
    "    for q_idx, q_code in enumerate(q_codes):\n",
    "        fn = filename_dataset(dataset, step=2, suffix='q_{}'.format(str(q_idx).zfill(3)))\n",
    "        \n",
    "        df_qry, q_code_2 = fn_to_ok_df(fn, return_qry=True)\n",
    "        target_id = list(range(df_qry.shape[1]))[target_idx] # Assumption: Last\n",
    "        \n",
    "        msg = \"\"\"\n",
    "        q_code from file: {}\n",
    "        q_code from data: {}\n",
    "        \"\"\".format(q_code, q_code_2)\n",
    "        #print(msg)\n",
    "        \n",
    "        assert(np.array_equal(q_code, q_code_2))\n",
    "        \n",
    "        test = df_qry.values\n",
    "        y_true = test[:,target_id].copy()\n",
    "        y_true = y_true.astype(int)\n",
    "        \n",
    "        df_qry.iloc[:, target_id] = np.nan\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = classifier.predict(df_qry,\n",
    "                                    qry_code=q_code,\n",
    "                                    pred_algo=prediction_algorithm,\n",
    "                                    pred_param=prediction_parameter,\n",
    "                                    pred_its=prediction_iterations)\n",
    "        \n",
    "        y_pred = y_pred.astype(int).ravel()\n",
    "        \n",
    "        f1 = f1_score(y_true, y_pred, average='micro')\n",
    "        result.append(f1)\n",
    "        \n",
    "    return q_codes, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 01 - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#FRACTION_MISSING = 0.3\n",
    "#ITERATIONS = 5\n",
    "MAX_DEPTH = 8\n",
    "MIN_SAMPLES_LEAF = 10\n",
    "\n",
    "datasets = ['iris',\n",
    "            'balance-scale',\n",
    "            'heart-statlog',\n",
    "            'glass',\n",
    "            'lymph',\n",
    "            'diabetes',\n",
    "            'vehicle',\n",
    "            'ionosphere',\n",
    "            'vowel']\n",
    "\n",
    "print(len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris\n",
      "4\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), [0, 1, 2, 3, 4])' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c405bf3b2ad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                                      \u001b[0mprediction_algorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                      \u001b[0mprediction_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                      prediction_parameter=0.95)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdataframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_codes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mercs-mi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-756860eb872b>\u001b[0m in \u001b[0;36mpredict_mercs\u001b[0;34m(dataset, classifier, target_idx, prediction_algorithm, prediction_iterations, prediction_parameter)\u001b[0m\n\u001b[1;32m     37\u001b[0m                                     \u001b[0mpred_algo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_algorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                                     \u001b[0mpred_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_parameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                                     pred_its=prediction_iterations)\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zissou/Repos/mercs/src/mercs/core/MERCS.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, q_idx, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m         )  # Generate X data\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# 4. Post processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zissou/Repos/mercs/src/mercs/models/PolyModel.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;31m# Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mmod_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_desc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;31m# Update X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zissou/miniconda3/envs/aaai20/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zissou/miniconda3/envs/aaai20/lib/python3.6/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_index_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"get_indexer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zissou/miniconda3/envs/aaai20/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 )\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), [0, 1, 2, 3, 4])' is an invalid key"
     ]
    }
   ],
   "source": [
    "dataframes = {k:[] for k in datasets}\n",
    "\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    clf = fit_mercs(ds,\n",
    "                    target_idx=-1,\n",
    "                    selection_algorithm=\"Base\",\n",
    "                    min_samples_leaf=MIN_SAMPLES_LEAF,\n",
    "                    max_depth=MAX_DEPTH)\n",
    "    \n",
    "    q_codes, results = predict_mercs(ds,\n",
    "                                     clf,\n",
    "                                     prediction_algorithm='mi',\n",
    "                                     prediction_iterations=0.1,\n",
    "                                     prediction_parameter=0.95)\n",
    "    \n",
    "    dataframes[ds] = collect_results(ds, q_codes, results, algorithm='mercs-mi')\n",
    "    \n",
    "df = process_outcomes(dataframes)\n",
    "save_outcome(df, filename='mercs-mi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 02 - SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_SL = {k:[] for k in datasets}\n",
    "\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    clf = fit_mercs(ds,\n",
    "                    target_idx=-1,\n",
    "                    selection_algorithm=\"Base\",\n",
    "                    min_samples_leaf=MIN_SAMPLES_LEAF,\n",
    "                    max_depth=MAX_DEPTH)\n",
    "    \n",
    "    q_codes, results = predict_mercs(ds,\n",
    "                                     clf,\n",
    "                                     prediction_algorithm='MAFI',\n",
    "                                     prediction_iterations=0.1,\n",
    "                                     prediction_parameter=0.95)\n",
    "    \n",
    "    dataframes[ds] = collect_results(ds, q_codes, results, algorithm='mercs-mrai')\n",
    "    \n",
    "df = process_outcomes(dataframes)\n",
    "save_outcome(df, filename='mercs-mrai')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 03 - ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_ML = {k:[] for k in datasets}\n",
    "\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    clf = fit_modulo(ds,\n",
    "                     target_idx=-1,\n",
    "                     random_state=RANDOM_STATE,\n",
    "                     prediction_algorithm='it',\n",
    "                     clf_criterion=\"entropy\",\n",
    "                     rgr_criterion=\"mae\",\n",
    "                     selection_algorithm=\"random\",\n",
    "                     nb_iterations=2,\n",
    "                     fraction_missing=[0, 0.1, 0.3],\n",
    "                     min_samples_leaf=10,\n",
    "                     max_steps=3)\n",
    "    \n",
    "    q_codes, results = predict_modulo(ds, clf)\n",
    "    \n",
    "    dataframes_ML[ds] = collect_results(ds, q_codes, results, algorithm='it')\n",
    "    \n",
    "df = process_outcomes(dataframes_ML)\n",
    "save_outcome(df, filename='ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaai20-belafonte",
   "language": "python",
   "name": "aaai20-belafonte"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
