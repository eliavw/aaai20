{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modulo Exp Def\n",
    "\n",
    "Final notebook which conducts the Modulo experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arff\n",
    "import os\n",
    "import numpy as np\n",
    "import aaai20\n",
    "#import PxW\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor, XGBRFRegressor\n",
    "\n",
    "from os.path import dirname\n",
    "from aaai20.io import filename_dataset, filename_query, filename_results\n",
    "from aaai20.exp import collect_results\n",
    "from aaai20.wrangling import arff_to_df\n",
    "from aaai20.exp import collect_results, process_outcomes, save_outcome\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mercs.core import Mercs as Modulo\n",
    "from mercs.utils.encoding import query_to_code, code_to_query, encode_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mercs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cw/dtailocal/repos/mercs/src/mercs/__init__.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mercs.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_to_ok_df(filename, encode=True):\n",
    "    \"\"\"\n",
    "    Convenience function. Preprocess so its ready for sklearn.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = arff_to_df(filename, return_af=False, encode_nominal=False)\n",
    "    qry = qry_from_df(df)\n",
    "    \n",
    "    if encode:\n",
    "        df_nominal = df.select_dtypes(exclude=['float'])\n",
    "        \n",
    "        label_encoders = {}\n",
    "        for c in df_nominal.columns:\n",
    "            label_encoders[c] = LabelEncoder()\n",
    "            label_encoders[c].fit(df_nominal[c])\n",
    "            df_nominal[c] = label_encoders[c].transform(df_nominal[c])\n",
    "\n",
    "        df[df_nominal.columns] = df_nominal.copy()    \n",
    "        nominal = df_nominal.columns.values\n",
    "\n",
    "        return df, qry, nominal, label_encoders\n",
    "    else:\n",
    "        return df, qry\n",
    "    \n",
    "def qry_from_df(df):\n",
    "    qry = np.zeros(len(df.columns), dtype=int)\n",
    "    \n",
    "    miss_ids = df.columns[df.isna().any()].tolist()\n",
    "    targ_ids = df.columns[-1]\n",
    "    \n",
    "    qry[miss_ids] = -1\n",
    "    qry[targ_ids] = 1\n",
    "    return qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_nominal(df):\n",
    "    df_nominal = df.select_dtypes(exclude=['float'])\n",
    "    \n",
    "    nominal = [idx for idx, c in enumerate(df) if c in df_nominal.columns]\n",
    "    \n",
    "    return nominal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_modulo(\n",
    "    dataset,\n",
    "    target_idx=-1,\n",
    "    random_state=42,\n",
    "    prediction_algorithm=\"mi\",\n",
    "    classifier_algorithm=\"DT\",\n",
    "    regressor_algorithm=\"DT\",\n",
    "    clf_criterion=\"gini\",\n",
    "    rgr_criterion=\"mse\",\n",
    "    selection_algorithm=\"base\",\n",
    "    nb_targets=1,\n",
    "    fraction_missing=0.2,\n",
    "    nb_iterations=1,\n",
    "    min_samples_leaf=2,\n",
    "    min_impurity_decrease=0.0,\n",
    "    max_steps=8,\n",
    "    max_depth=None,\n",
    "    n_estimators=10,\n",
    "):\n",
    "\n",
    "    # Preliminaries\n",
    "    fn_train = filename_dataset(dataset, step=1, suffix=\"train\", extension=\"csv\")\n",
    "    df = pd.read_csv(fn_train, header=None, index_col=None)\n",
    "    train = df.values\n",
    "\n",
    "    nominal = detect_nominal(df)\n",
    "\n",
    "    msg = \"\"\"\n",
    "    Nominal attributes detected in dataset: {}\n",
    "    Nominal: {}\n",
    "    \"\"\".format(\n",
    "        dataset, nominal\n",
    "    )\n",
    "    # print(msg)\n",
    "\n",
    "    target_id = list(range(df.shape[1]))[\n",
    "        target_idx\n",
    "    ]  # Assumption: Last attribute is target\n",
    "    nominal_ids = set(list(nominal) + [target_id])\n",
    "    # print(nominal_ids)\n",
    "\n",
    "    # Train\n",
    "    clf = Modulo(\n",
    "        random_state=random_state,\n",
    "        nb_targets=nb_targets,\n",
    "        classifier_algorithm=classifier_algorithm,\n",
    "        regressor_algorithm=regressor_algorithm,\n",
    "        prediction_algorithm=prediction_algorithm,\n",
    "        clf_criterion=clf_criterion,\n",
    "        rgr_criterion=rgr_criterion,\n",
    "        selection_algorithm=selection_algorithm,\n",
    "        fraction_missing=fraction_missing,\n",
    "        nb_iterations=nb_iterations,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        min_impurity_decrease=min_impurity_decrease,\n",
    "        max_depth=max_depth,\n",
    "        max_steps=max_steps,\n",
    "        n_estimators=n_estimators,\n",
    "    )\n",
    "\n",
    "    clf.fit(train, nominal_attributes=nominal_ids)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_modulo(dataset, classifier, target_idx=-1, prediction_algorithm=None, **prediction_kwargs):\n",
    "    result = {}\n",
    "    f1_micro = []\n",
    "    f1_macro = []\n",
    "    \n",
    "    # Load queries\n",
    "    fn_qry = filename_query(dataset, suffix=\"default\")\n",
    "    q_codes = np.load(fn_qry)\n",
    "    q_codes_return = q_codes.copy()\n",
    "    \n",
    "    for q_idx, q_code in enumerate(q_codes):\n",
    "        fn = filename_dataset(dataset, step=2, suffix='q_{}'.format(str(q_idx).zfill(3)), extension='csv')\n",
    "        df_qry = pd.read_csv(fn, header=None, index_col=None)\n",
    "        \n",
    "        #print(df_qry.head())\n",
    "        q_code_2 = qry_from_df(df_qry)\n",
    "\n",
    "        target_id = list(range(df_qry.shape[1]))[target_idx] # Assumption: Last\n",
    "        \n",
    "        msg = \"\"\"\n",
    "        q_code from file: {}\n",
    "        q_code from data: {}\n",
    "        \"\"\".format(q_code, q_code_2)\n",
    "        #print(msg)\n",
    "        \n",
    "        assert(np.array_equal(q_code, q_code_2))\n",
    "        \n",
    "        test = df_qry.values\n",
    "        y_true = test[:,target_id].copy()\n",
    "        #y_true = y_true.astype(int)\n",
    "        test[:, target_id] = np.nan\n",
    "        \n",
    "        if prediction_algorithm is None:\n",
    "            y_pred = classifier.predict(test, q_code=q_code)\n",
    "        else:\n",
    "            y_pred = classifier.predict(test, q_code=q_code, prediction_algorithm=prediction_algorithm, **prediction_kwargs)\n",
    "\n",
    "        f1_micro.append(f1_score(y_true, y_pred, average='micro'))\n",
    "        f1_macro.append(f1_score(y_true, y_pred, average='macro'))\n",
    "    \n",
    "    result['f1_micro'] = f1_micro\n",
    "    result['f1_macro'] = f1_macro\n",
    "        \n",
    "    return q_codes_return, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(ds):\n",
    "    clf = fit_modulo(ds,\n",
    "                     target_idx=-1,\n",
    "                     random_state=RANDOM_STATE,\n",
    "                     classifier_algorithm=\"DT\",\n",
    "                     regressor_algorithm=\"DT\",\n",
    "                     nb_targets=1,\n",
    "                     selection_algorithm=\"random\",\n",
    "                     nb_iterations=ITERATIONS,\n",
    "                     fraction_missing=FRACTION_MISSING,\n",
    "                     max_depth=MAX_DEPTH,\n",
    "                     #clf_criterion=\"gini\",\n",
    "                     #rgr_criterion=\"friedman_mse\",\n",
    "                     #min_samples_leaf=MIN_SAMPLES_LEAF,\n",
    "                     )\n",
    "\n",
    "    q_codes, results = predict_modulo(ds, clf, prediction_algorithm='mi')\n",
    "    mi = collect_results(ds, q_codes, results, identifier='sklearn')\n",
    "    print(\"mi done\")\n",
    "\n",
    "    _, results = predict_modulo(ds, clf, prediction_algorithm='mrai',)\n",
    "    mrai = collect_results(ds, q_codes, results, identifier='mrai')\n",
    "    print(\"mrai done\")\n",
    "\n",
    "    _, results = predict_modulo(ds, clf, prediction_algorithm='it', max_steps=10, stepsize=0.2)\n",
    "    it = collect_results(ds, q_codes, results, identifier='it')\n",
    "    print(\"it done\")\n",
    "    \n",
    "    _, results = predict_modulo(ds, clf, prediction_algorithm='rw', max_steps=10, nb_walks=40)\n",
    "    rw = collect_results(ds, q_codes, results, identifier='rw')\n",
    "    print(\"rw done\")\n",
    "    return mi, mrai, it, rw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "FRACTION_MISSING = [0.3,]\n",
    "ITERATIONS = 5\n",
    "\n",
    "RANDOM_STATE = 98\n",
    "MAX_DEPTH = 8\n",
    "\n",
    "datasets = ['glass',\n",
    "             'credit-g',\n",
    "             'ionosphere',\n",
    "             'lymph',\n",
    "             'vehicle',\n",
    "             'iris',\n",
    "             'splice',\n",
    "             'sonar',\n",
    "             'vowel',\n",
    "             'segment',\n",
    "             'zoo',\n",
    "             'heart-statlog',\n",
    "             'waveform-5000',\n",
    "             'kr-vs-kp',\n",
    "             'diabetes',\n",
    "             'letter',\n",
    "             'balance-scale']\n",
    "\n",
    "print(len(datasets))\n",
    "\n",
    " m_list = Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(_learn_model)(*t, **k) for t, k in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   1 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  17 | elapsed:   59.8s remaining:  4.7min\n",
      "[Parallel(n_jobs=8)]: Done   4 out of  17 | elapsed:  1.1min remaining:  3.4min\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  17 | elapsed:  1.3min remaining:  3.2min\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  17 | elapsed:  1.4min remaining:  2.5min\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  17 | elapsed:  1.6min remaining:  2.3min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of  17 | elapsed:  1.6min remaining:  1.8min\n",
      "[Parallel(n_jobs=8)]: Done   9 out of  17 | elapsed:  1.6min remaining:  1.4min\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  17 | elapsed:  1.6min remaining:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done  11 out of  17 | elapsed:  1.6min remaining:   52.0s\n",
      "[Parallel(n_jobs=8)]: Done  12 out of  17 | elapsed:  1.6min remaining:   39.8s\n",
      "[Parallel(n_jobs=8)]: Done  13 out of  17 | elapsed:  1.6min remaining:   29.4s\n",
      "[Parallel(n_jobs=8)]: Done  14 out of  17 | elapsed:  1.6min remaining:   20.4s\n",
      "[Parallel(n_jobs=8)]: Done  15 out of  17 | elapsed:  1.6min remaining:   12.7s\n",
      "[Parallel(n_jobs=8)]: Done  17 out of  17 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-040ad03eb53b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m51\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/elia/miniconda3/envs/aaai20/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elia/miniconda3/envs/aaai20/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elia/miniconda3/envs/aaai20/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elia/miniconda3/envs/aaai20/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elia/miniconda3/envs/aaai20/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "dfs =  Parallel(n_jobs=8, verbose=51)(delayed(run_experiment)(ds) for ds in datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_01 = {k:[] for k in datasets}\n",
    "dfs_02 = {k:[] for k in datasets}\n",
    "dfs_03 = {k:[] for k in datasets}\n",
    "dfs_04 = {k:[] for k in datasets}\n",
    "\n",
    "for (mi, mrai, it, rw), ds in zip(dfs, datasets):\n",
    "    dfs_01[ds] = mi\n",
    "    dfs_02[ds] = mrai\n",
    "    dfs_03[ds] = it\n",
    "    dfs_04[ds] = rw\n",
    "    \n",
    "for dataframes, algo in zip((dfs_01, dfs_02, dfs_03, dfs_04), ('mi', 'mrai', 'it', 'rw')):\n",
    "    df = process_outcomes(dataframes)\n",
    "    \n",
    "    fn = filename_results(exp_dname='mercs-vs-weka', exp_fname=algo)\n",
    "    df.to_csv(fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaai20.__file__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaai20-frost",
   "language": "python",
   "name": "aaai20-frost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
