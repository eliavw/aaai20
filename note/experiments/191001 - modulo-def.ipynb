{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modulo Exp Def\n",
    "\n",
    "Final notebook which conducts the Modulo experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arff\n",
    "import os\n",
    "import numpy as np\n",
    "import aaai20\n",
    "#import PxW\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor, XGBRFRegressor\n",
    "\n",
    "from os.path import dirname\n",
    "from aaai20.io import filename_dataset, filename_query, filename_results\n",
    "from aaai20.exp import collect_results\n",
    "from aaai20.wrangling import arff_to_df\n",
    "from aaai20.exp import collect_results, process_outcomes, save_outcome\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mercs.core import Mercs as Modulo\n",
    "from mercs.utils.encoding import query_to_code, code_to_query, encode_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mercs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cw/dtaijupiter/NoCsBack/dtai/elia/mercs/src/mercs/__init__.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mercs.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_to_ok_df(filename, encode=True):\n",
    "    \"\"\"\n",
    "    Convenience function. Preprocess so its ready for sklearn.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = arff_to_df(filename, return_af=False, encode_nominal=False)\n",
    "    qry = qry_from_df(df)\n",
    "    \n",
    "    if encode:\n",
    "        df_nominal = df.select_dtypes(exclude=['float'])\n",
    "        \n",
    "        label_encoders = {}\n",
    "        for c in df_nominal.columns:\n",
    "            label_encoders[c] = LabelEncoder()\n",
    "            label_encoders[c].fit(df_nominal[c])\n",
    "            df_nominal[c] = label_encoders[c].transform(df_nominal[c])\n",
    "\n",
    "        df[df_nominal.columns] = df_nominal.copy()    \n",
    "        nominal = df_nominal.columns.values\n",
    "\n",
    "        return df, qry, nominal, label_encoders\n",
    "    else:\n",
    "        return df, qry\n",
    "    \n",
    "def qry_from_df(df):\n",
    "    qry = np.zeros(len(df.columns), dtype=int)\n",
    "    \n",
    "    miss_ids = df.columns[df.isna().any()].tolist()\n",
    "    targ_ids = df.columns[-1]\n",
    "    \n",
    "    qry[miss_ids] = -1\n",
    "    qry[targ_ids] = 1\n",
    "    return qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_nominal(df):\n",
    "    df_nominal = df.select_dtypes(exclude=['float'])\n",
    "    \n",
    "    nominal = [idx for idx, c in enumerate(df) if c in df_nominal.columns]\n",
    "    \n",
    "    return nominal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_modulo(\n",
    "    dataset,\n",
    "    target_idx=-1,\n",
    "    random_state=42,\n",
    "    prediction_algorithm=\"mi\",\n",
    "    classifier_algorithm=\"DT\",\n",
    "    regressor_algorithm=\"DT\",\n",
    "    #clf_criterion=\"gini\",\n",
    "    #rgr_criterion=\"mse\",\n",
    "    selection_algorithm=\"base\",\n",
    "    nb_targets=1,\n",
    "    fraction_missing=0.2,\n",
    "    nb_iterations=1,\n",
    "    min_samples_leaf=2,\n",
    "    min_impurity_decrease=0.0,\n",
    "    max_steps=8,\n",
    "    max_depth=None,\n",
    "    n_estimators=10,\n",
    "):\n",
    "\n",
    "    # Preliminaries\n",
    "    fn_train = filename_dataset(dataset, step=1, suffix=\"train\", extension=\"csv\")\n",
    "    df = pd.read_csv(fn_train, header=None, index_col=None)\n",
    "    train = df.values\n",
    "\n",
    "    nominal = detect_nominal(df)\n",
    "\n",
    "    msg = \"\"\"\n",
    "    Nominal attributes detected in dataset: {}\n",
    "    Nominal: {}\n",
    "    \"\"\".format(\n",
    "        dataset, nominal\n",
    "    )\n",
    "    # print(msg)\n",
    "\n",
    "    target_id = list(range(df.shape[1]))[\n",
    "        target_idx\n",
    "    ]  # Assumption: Last attribute is target\n",
    "    nominal_ids = set(list(nominal) + [target_id])\n",
    "    # print(nominal_ids)\n",
    "\n",
    "    # Train\n",
    "    clf = Modulo(\n",
    "        random_state=random_state,\n",
    "        nb_targets=nb_targets,\n",
    "        classifier_algorithm=classifier_algorithm,\n",
    "        regressor_algorithm=regressor_algorithm,\n",
    "        prediction_algorithm=prediction_algorithm,\n",
    "        #clf_criterion=clf_criterion,\n",
    "        #rgr_criterion=rgr_criterion,\n",
    "        selection_algorithm=selection_algorithm,\n",
    "        fraction_missing=fraction_missing,\n",
    "        nb_iterations=nb_iterations,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        min_impurity_decrease=min_impurity_decrease,\n",
    "        max_depth=max_depth,\n",
    "        max_steps=max_steps,\n",
    "        n_estimators=n_estimators,\n",
    "    )\n",
    "\n",
    "    clf.fit(train, nominal_attributes=nominal_ids)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_modulo(dataset, classifier, target_idx=-1, prediction_algorithm=None, **prediction_kwargs):\n",
    "    result = {}\n",
    "    f1_micro = []\n",
    "    f1_macro = []\n",
    "    accuracy = []\n",
    "    \n",
    "    # Load queries\n",
    "    fn_qry = filename_query(dataset, suffix=\"default\")\n",
    "    q_codes = np.load(fn_qry)\n",
    "    q_codes_return = q_codes.copy()\n",
    "    \n",
    "    for q_idx, q_code in enumerate(q_codes):\n",
    "        fn = filename_dataset(dataset, step=2, suffix='q_{}'.format(str(q_idx).zfill(3)), extension='csv')\n",
    "        df_qry = pd.read_csv(fn, header=None, index_col=None)\n",
    "        \n",
    "        #print(df_qry.head())\n",
    "        q_code_2 = qry_from_df(df_qry)\n",
    "\n",
    "        target_id = list(range(df_qry.shape[1]))[target_idx] # Assumption: Last\n",
    "        \n",
    "        msg = \"\"\"\n",
    "        q_code from file: {}\n",
    "        q_code from data: {}\n",
    "        \"\"\".format(q_code, q_code_2)\n",
    "        #print(msg)\n",
    "        \n",
    "        assert(np.array_equal(q_code, q_code_2))\n",
    "        \n",
    "        test = df_qry.values\n",
    "        y_true = test[:,target_id].copy()\n",
    "        #y_true = y_true.astype(int)\n",
    "        test[:, target_id] = np.nan\n",
    "        \n",
    "        if prediction_algorithm is None:\n",
    "            y_pred = classifier.predict(test, q_code=q_code)\n",
    "        else:\n",
    "            y_pred = classifier.predict(test, q_code=q_code, prediction_algorithm=prediction_algorithm, **prediction_kwargs)\n",
    "\n",
    "        accuracy.append(accuracy_score(y_true, y_pred))\n",
    "        f1_micro.append(f1_score(y_true, y_pred, average='micro'))\n",
    "        f1_macro.append(f1_score(y_true, y_pred, average='macro'))\n",
    "    \n",
    "    result['accuracy'] = accuracy\n",
    "    result['f1_micro'] = f1_micro\n",
    "    result['f1_macro'] = f1_macro\n",
    "        \n",
    "    return q_codes_return, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(ds):\n",
    "    clf = fit_modulo(ds,\n",
    "                     target_idx=-1,\n",
    "                     random_state=RANDOM_STATE,\n",
    "                     classifier_algorithm=\"DT\",\n",
    "                     regressor_algorithm=\"DT\",\n",
    "                     nb_targets=NB_TARGETS,\n",
    "                     selection_algorithm=SELECTION_ALGORITHM,\n",
    "                     nb_iterations=ITERATIONS,\n",
    "                     fraction_missing=FRACTION_MISSING,\n",
    "                     max_depth=MAX_DEPTH,\n",
    "                     #clf_criterion=\"gini\",\n",
    "                     #rgr_criterion=\"friedman_mse\",\n",
    "                     #min_samples_leaf=MIN_SAMPLES_LEAF,\n",
    "                     )\n",
    "\n",
    "    q_codes, results = predict_modulo(ds, clf, prediction_algorithm='mi')\n",
    "    mi = collect_results(ds, q_codes, results, identifier='mi')\n",
    "    print(\"mi done\")\n",
    "\n",
    "    _, results = predict_modulo(ds, clf, prediction_algorithm='mrai',)\n",
    "    mrai = collect_results(ds, q_codes, results, identifier='mrai')\n",
    "    print(\"mrai done\")\n",
    "\n",
    "    _, results = predict_modulo(ds, clf, prediction_algorithm='it', max_steps=8)\n",
    "    it = collect_results(ds, q_codes, results, identifier='it')\n",
    "    print(\"it done\")\n",
    "    \n",
    "    _, results = predict_modulo(ds, clf, prediction_algorithm='rw', max_steps=8, nb_walks=30)\n",
    "    rw = collect_results(ds, q_codes, results, identifier='rw')\n",
    "    print(\"rw done\")\n",
    "    return mi, mrai, it, rw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# Parallel\n",
    "n_jobs=8\n",
    "verbose=51\n",
    "\n",
    "SELECTION_ALGORITHM = \"random\"\n",
    "FRACTION_MISSING = [0.3, 0.6, 0.8]\n",
    "MAX_DEPTH = 8\n",
    "ITERATIONS = 10\n",
    "NB_TARGETS = 1\n",
    "RANDOM_STATE = 98\n",
    "\n",
    "\n",
    "datasets = ['glass',\n",
    "             'credit-g',\n",
    "             'ionosphere',\n",
    "             'lymph',\n",
    "             'vehicle',\n",
    "             'iris',\n",
    "             'splice',\n",
    "             'sonar',\n",
    "             'vowel',\n",
    "             'segment',\n",
    "             'zoo',\n",
    "             'heart-statlog',\n",
    "             'waveform-5000',\n",
    "             'kr-vs-kp',\n",
    "             'diabetes',\n",
    "             'letter',\n",
    "             'balance-scale']\n",
    "\n",
    "print(len(datasets))\n",
    "\n",
    "#m_list = Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(_learn_model)(*t, **k) for t, k in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs = [run_experiment(ds) for ds in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   1 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  17 | elapsed:   10.5s remaining:   48.9s\n",
      "[Parallel(n_jobs=8)]: Done   4 out of  17 | elapsed:   12.2s remaining:   39.6s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  17 | elapsed:   12.7s remaining:   30.4s\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  17 | elapsed:   13.2s remaining:   24.3s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  17 | elapsed:   18.5s remaining:   26.4s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of  17 | elapsed:   19.2s remaining:   21.6s\n",
      "[Parallel(n_jobs=8)]: Done   9 out of  17 | elapsed:   19.4s remaining:   17.3s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  17 | elapsed:   22.3s remaining:   15.6s\n",
      "[Parallel(n_jobs=8)]: Done  11 out of  17 | elapsed:   23.8s remaining:   13.0s\n",
      "[Parallel(n_jobs=8)]: Done  12 out of  17 | elapsed:   25.2s remaining:   10.5s\n",
      "[Parallel(n_jobs=8)]: Done  13 out of  17 | elapsed:   30.1s remaining:    9.3s\n",
      "[Parallel(n_jobs=8)]: Done  14 out of  17 | elapsed:   31.2s remaining:    6.7s\n",
      "[Parallel(n_jobs=8)]: Done  15 out of  17 | elapsed:   43.2s remaining:    5.8s\n",
      "[Parallel(n_jobs=8)]: Done  17 out of  17 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  17 out of  17 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "dfs =  Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(run_experiment)(ds) for ds in datasets)\n",
    "\n",
    "# Save\n",
    "dfs_01 = {k:[] for k in datasets}\n",
    "dfs_02 = {k:[] for k in datasets}\n",
    "dfs_03 = {k:[] for k in datasets}\n",
    "dfs_04 = {k:[] for k in datasets}\n",
    "\n",
    "for (mi, mrai, it, rw), ds in zip(dfs, datasets):\n",
    "    dfs_01[ds] = mi\n",
    "    dfs_02[ds] = mrai\n",
    "    dfs_03[ds] = it\n",
    "    dfs_04[ds] = rw\n",
    "    \n",
    "for dataframes, algo in zip((dfs_01, dfs_02, dfs_03, dfs_04), ('mi', 'mrai', 'it', 'rw')):\n",
    "    df = process_outcomes(dataframes)\n",
    "    \n",
    "    fn = filename_results(exp_dname='mercs-vs-weka', exp_fname=algo)\n",
    "    df.to_csv(fn, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaai20-frost",
   "language": "python",
   "name": "aaai20-frost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
