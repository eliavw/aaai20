{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Weka Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PxW\n",
    "import pandas as pd\n",
    "import arff\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import dirname\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def filename(basename, step=1, prefix=\"\", suffix=\"\", extension=\"arff\", check=True):\n",
    "    \n",
    "    filename = \"-\".join([x for x in (prefix, basename, suffix) if len(x) > 0])+\".{}\".format(extension)\n",
    "    \n",
    "    root_dir = dirname(os.getcwd())\n",
    "    data_dir = os.path.relpath(os.path.join(root_dir, 'data'))\n",
    "    step_dir = os.path.join(data_dir, \"step-\"+str(step).zfill(2))\n",
    "\n",
    "    if check:\n",
    "        if not os.path.exists(step_dir):\n",
    "            os.makedirs(step_dir)\n",
    "    \n",
    "\n",
    "    return os.path.join(step_dir, filename)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_weka(out, average='macro'):\n",
    "    out = out.apply(LabelEncoder().fit_transform)\n",
    "    f1 = f1_score(out['actual'], out['predicted'], average=average)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = dirname(os.getcwd())\n",
    "data_dir = os.path.relpath(os.path.join(root_dir, 'data'))\n",
    "\n",
    "step = 2 # Where final datasets reside.\n",
    "step_dir = os.path.join(data_dir, \"step-\"+str(step).zfill(2))\n",
    "\n",
    "datasets = ['iris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-08-28 10:26:40,630] INFO - prefect.FlowRunner | Beginning Flow run for 'fit'\n",
      "[2019-08-28 10:26:40,632] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2019-08-28 10:26:40,641] INFO - prefect.TaskRunner | Task 'Constant[str]': Starting task run...\n",
      "[2019-08-28 10:26:40,643] INFO - prefect.TaskRunner | Task 'Constant[str]': finished task run for task with final state: 'Success'\n",
      "[2019-08-28 10:26:40,644] INFO - prefect.TaskRunner | Task 'ShellTask': Starting task run...\n",
      "[2019-08-28 10:26:41,090] INFO - prefect.TaskRunner | Task 'ShellTask': finished task run for task with final state: 'Success'\n",
      "[2019-08-28 10:26:41,093] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n",
      "[2019-08-28 10:26:41,096] INFO - prefect.FlowRunner | Beginning Flow run for 'predict'\n",
      "[2019-08-28 10:26:41,097] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2019-08-28 10:26:41,102] INFO - prefect.TaskRunner | Task 'Constant[str]': Starting task run...\n",
      "[2019-08-28 10:26:41,103] INFO - prefect.TaskRunner | Task 'Constant[str]': finished task run for task with final state: 'Success'\n",
      "[2019-08-28 10:26:41,104] INFO - prefect.TaskRunner | Task 'ShellTask': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "../data/step-02/iris-q_000.arff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-08-28 10:26:41,321] INFO - prefect.TaskRunner | Task 'ShellTask': finished task run for task with final state: 'Success'\n",
      "[2019-08-28 10:26:41,322] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n",
      "[2019-08-28 10:26:41,341] INFO - prefect.FlowRunner | Beginning Flow run for 'predict'\n",
      "[2019-08-28 10:26:41,342] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2019-08-28 10:26:41,346] INFO - prefect.TaskRunner | Task 'Constant[str]': Starting task run...\n",
      "[2019-08-28 10:26:41,348] INFO - prefect.TaskRunner | Task 'Constant[str]': finished task run for task with final state: 'Success'\n",
      "[2019-08-28 10:26:41,349] INFO - prefect.TaskRunner | Task 'ShellTask': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "../data/step-02/iris-q_001.arff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-08-28 10:26:41,565] INFO - prefect.TaskRunner | Task 'ShellTask': finished task run for task with final state: 'Success'\n",
      "[2019-08-28 10:26:41,568] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n",
      "/home/zissou/miniconda3/envs/aaai20/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[2019-08-28 10:26:41,580] INFO - prefect.FlowRunner | Beginning Flow run for 'predict'\n",
      "[2019-08-28 10:26:41,581] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2019-08-28 10:26:41,586] INFO - prefect.TaskRunner | Task 'Constant[str]': Starting task run...\n",
      "[2019-08-28 10:26:41,588] INFO - prefect.TaskRunner | Task 'Constant[str]': finished task run for task with final state: 'Success'\n",
      "[2019-08-28 10:26:41,589] INFO - prefect.TaskRunner | Task 'ShellTask': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "../data/step-02/iris-q_002.arff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-08-28 10:26:41,819] INFO - prefect.TaskRunner | Task 'ShellTask': finished task run for task with final state: 'Success'\n",
      "[2019-08-28 10:26:41,820] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n",
      "/home/zissou/miniconda3/envs/aaai20/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[2019-08-28 10:26:41,834] INFO - prefect.FlowRunner | Beginning Flow run for 'predict'\n",
      "[2019-08-28 10:26:41,835] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2019-08-28 10:26:41,842] INFO - prefect.TaskRunner | Task 'Constant[str]': Starting task run...\n",
      "[2019-08-28 10:26:41,845] INFO - prefect.TaskRunner | Task 'Constant[str]': finished task run for task with final state: 'Success'\n",
      "[2019-08-28 10:26:41,846] INFO - prefect.TaskRunner | Task 'ShellTask': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "../data/step-02/iris-q_003.arff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-08-28 10:26:42,078] INFO - prefect.TaskRunner | Task 'ShellTask': finished task run for task with final state: 'Success'\n",
      "[2019-08-28 10:26:42,079] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n",
      "/home/zissou/miniconda3/envs/aaai20/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for ds in datasets:\n",
    "    \n",
    "    # Train\n",
    "    fn_train = filename(ds, step=1, suffix='train')\n",
    "    clf = PxW.J48()\n",
    "    clf.fit(fn_train, verbose=False)\n",
    "    \n",
    "    # Test\n",
    "    fn_qry = [os.path.join(step_dir, fn) for fn in os.listdir(step_dir) if ds in fn]\n",
    "    fn_qry.sort()\n",
    "    \n",
    "    for q_idx, fn in enumerate(fn_qry):\n",
    "        print(q_idx)\n",
    "        print(fn)\n",
    "        out = clf.predict(fn, verbose=True)\n",
    "        f1 = f1_weka(out, average='macro')\n",
    "        res.append(f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9665831244778613,\n",
       " 0.2501414827391058,\n",
       " 0.2501414827391058,\n",
       " 0.2501414827391058]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaai20-belafonte",
   "language": "python",
   "name": "aaai20-belafonte"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
