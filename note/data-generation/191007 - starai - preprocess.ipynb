{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StarAI datasets Preprocessing.\n",
    "\n",
    "The flow will be as follows:\n",
    "\n",
    "    1. raw -> step-01\n",
    "        Convert .data to .csv\n",
    "        Drop constant columns\n",
    "    2. step-01 -> step-02\n",
    "        Make a PxS alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from os.path import dirname\n",
    "from aaai20.io import filename_dataset, filename_query, original_filename\n",
    "from aaai20.wrangling import arff_to_df\n",
    "\n",
    "RANDOM_STATE = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_constant_columns(dfs):\n",
    "    try:\n",
    "        result = []\n",
    "        for df in iter(dfs):\n",
    "            result += detect_constant_columns(df)\n",
    "        return result\n",
    "    except TypeError:    \n",
    "        # We assume a single dataframe was passed\n",
    "        return [col for col in dfs if dfs[col].nunique() < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def headers_pxs(df):\n",
    "    return [\"att_{}\".format(x) for x in df.columns.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_to_step_01(ds):\n",
    "\n",
    "    # Load in memory\n",
    "    fn_train, fn_test = (\n",
    "        original_filename(\n",
    "            ds, category=\"starai\", extension=\"data\", train_or_test=\"train\"\n",
    "        ),\n",
    "        original_filename(\n",
    "            ds, category=\"starai\", extension=\"data\", train_or_test=\"test\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    df_train, df_test = (\n",
    "        pd.read_csv(fn_train, header=None),\n",
    "        pd.read_csv(fn_test, header=None),\n",
    "    )\n",
    "\n",
    "    # Remove constant columns\n",
    "    constant_columns = detect_constant_columns([df_train, df_test])\n",
    "    df_train, df_test = (\n",
    "        df_train.drop(constant_columns, axis=1),\n",
    "        df_test.drop(constant_columns, axis=1),\n",
    "    )\n",
    "    assert df_train.columns.equals(df_test.columns)\n",
    "\n",
    "    # Save files\n",
    "    extension = \"csv\"\n",
    "    fn_train, fn_test = (\n",
    "        filename_dataset(ds, step=1, suffix=\"train\", extension=extension),\n",
    "        filename_dataset(ds, step=1, suffix=\"test\", extension=extension),\n",
    "    )\n",
    "\n",
    "    df_train.to_csv(fn_train, index=False, header=False)\n",
    "    df_test.to_csv(fn_test, index=False, header=False)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_01_to_step_02(ds):\n",
    "    # Load in memory\n",
    "    extension = 'csv'\n",
    "    fn_train, fn_test = (\n",
    "        filename_dataset(ds, step=1, suffix=\"train\", extension=extension),\n",
    "        filename_dataset(ds, step=1, suffix=\"test\", extension=extension),\n",
    "    )\n",
    "\n",
    "    df_train, df_test = (\n",
    "        pd.read_csv(fn_train, header=None),\n",
    "        pd.read_csv(fn_test, header=None),\n",
    "    )\n",
    "\n",
    "    # Create PxS Headers\n",
    "    pxs_headers = headers_pxs(df_train)\n",
    "    assert pxs_headers == headers_pxs(df_test)\n",
    "\n",
    "    # Save\n",
    "\n",
    "    fn_mercs_train, fn_mercs_test = (\n",
    "        filename_dataset(ds, step=2, suffix=\"train\", extension=extension),\n",
    "        filename_dataset(ds, step=2, suffix=\"test\", extension=extension),\n",
    "    )\n",
    "    df_train.to_csv(fn_mercs_train, index=False, header=False)\n",
    "    df_test.to_csv(fn_mercs_test, index=False, header=False)\n",
    "\n",
    "    suffix = \"pxs\"\n",
    "    fn_pxs_train, fn_pxs_test = (\n",
    "        filename_dataset(ds, step=2, suffix=[\"train\", suffix], extension=extension),\n",
    "        filename_dataset(ds, step=2, suffix=[\"test\", suffix], extension=extension),\n",
    "    )\n",
    "\n",
    "    df_train.columns, df_test.columns = pxs_headers, pxs_headers\n",
    "\n",
    "    df_train.to_csv(fn_pxs_train, index=False)\n",
    "    df_test.to_csv(fn_pxs_test, index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw -> step-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_filename(\"accidents\", category=\"starai\", extension=\"data\")\n",
    "\n",
    "\n",
    "ds = \"nltcs\"\n",
    "\n",
    "raw_to_step_01(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step-01 -> step 02\n",
    "\n",
    "Creating the PxS headers now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_01_to_step_02(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cwebkb', 'book', 'bbc', 'kdd', 'ad', 'msnbc', 'tretail', 'msweb', 'jester', 'pumsb_star', 'baudio', 'nltcs', 'plants', 'dna', 'bnetflix', 'voting', 'cr52', 'c20ng', 'kosarek', 'accidents', 'tmovie']\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "starai_datasets = os.listdir(dirname(dirname(original_filename('nltcs', category='starai'))))\n",
    "print(starai_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 01 done\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=7)(delayed(raw_to_step_01)(ds) for ds in starai_datasets)\n",
    "\n",
    "print(\"step 01 done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 02 done\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=7)(delayed(step_01_to_step_02)(ds) for ds in starai_datasets)\n",
    "\n",
    "print(\"step 02 done\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for ds in starai_datasets:\n",
    "    \n",
    "    raw_to_step_01(ds)\n",
    "    step_01_to_step_02(ds)\n",
    "    \n",
    "    msg = \"\"\"\n",
    "    Dataset {} done.\n",
    "    \"\"\"\n",
    "    print(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaai20-frost",
   "language": "python",
   "name": "aaai20-frost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
