{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "This notebook will evolve into the preprocess script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arff\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import dirname\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_filename(basename, extension='arff'):\n",
    "    \n",
    "    root_dir = dirname(os.getcwd())\n",
    "    true_path = os.path.join(root_dir, 'data', 'raw', 'datasets-UCI', 'UCI', \"{}.{}\".format(basename, extension))\n",
    "\n",
    "    return os.path.relpath(true_path)\n",
    "\n",
    "def filename(basename, step=1, prefix=\"\", suffix=\"\", seperator=\"-\", extension=\"arff\", check=True):\n",
    "    \"\"\"\n",
    "    Filename generator for the datafiles of this experiment\n",
    "    \"\"\"\n",
    "    \n",
    "    filename = build_filename(basename, prefix=prefix, suffix=suffix, separator=seperator, extension=extension)\n",
    "    \n",
    "    # FS things\n",
    "    root_dir = dirname(os.getcwd())\n",
    "    data_dir = os.path.relpath(os.path.join(root_dir, 'data'))\n",
    "    step_dir = os.path.join(data_dir, \"step-\"+str(step).zfill(2))\n",
    "\n",
    "    # If dir does not exist, make it\n",
    "    if check:\n",
    "        if not os.path.exists(step_dir):\n",
    "            os.makedirs(step_dir)\n",
    "\n",
    "    return os.path.join(step_dir, filename)\n",
    "\n",
    "def filename_query(basename, prefix=\"\", suffix=\"\", seperator=\"-\", extension=\"npy\", check=True):\n",
    "    \"\"\"\n",
    "    Filename generator of the query files of this experiment\n",
    "    \"\"\"\n",
    "    filename = build_filename(basename, prefix=prefix, suffix=suffix, separator=seperator, extension=extension)\n",
    "    \n",
    "    # FS things\n",
    "    root_dir = dirname(os.getcwd())\n",
    "    conf_dir = os.path.relpath(os.path.join(root_dir, 'config'))\n",
    "    qry_dir = os.path.join(data_dir, \"query\")\n",
    "\n",
    "    # If dir does not exist, make it\n",
    "    if check:\n",
    "        if not os.path.exists(qry_dir):\n",
    "            os.makedirs(qry_dir)\n",
    "\n",
    "    return os.path.join(qry_dir, filename)\n",
    "\n",
    "\n",
    "def build_filename(basename, prefix=\"\", suffix=\"\", separator=\"-\", extension=\"csv\"):\n",
    "    return separator.join([x for x in (prefix, basename, suffix) if len(x) > 0])+\".{}\".format(extension)\n",
    "\n",
    "\n",
    "def arff_to_df(filename, encode_nominal=False, return_af=True):\n",
    "    with open(filename, 'r') as f:\n",
    "        af = arff.load(f, encode_nominal=encode_nominal)\n",
    "    \n",
    "    df = pd.DataFrame(af['data'])\n",
    "    \n",
    "    if return_af:\n",
    "        return df, af\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 - Train-Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = 'iris'\n",
    "fn_inn = original_filename(dataset)\n",
    "\n",
    "df, af = arff_to_df(fn_inn, encode_nominal=False, return_af=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames\n",
    "fn_train = filename(dataset, step=1, suffix='train')\n",
    "fn_test = filename(dataset, step=1, suffix='test')\n",
    "\n",
    "# split train and test\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=RANDOM_STATE, stratify=df.iloc[:, -1:])\n",
    "\n",
    "af_train = af.copy()\n",
    "af_train['data'] = train.values\n",
    "\n",
    "with open(fn_train, 'w') as f:\n",
    "    arff.dump(af_train, f)\n",
    "    \n",
    "af_test = af.copy()\n",
    "af_test['data'] = test.values\n",
    "\n",
    "with open(fn_test, 'w') as f:\n",
    "    arff.dump(af_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate test\n",
    "\n",
    "Now we should see if these in fact can be used to train a weka model, or if there are some fishy things going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/step-01/iris-train.arff'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-08-29 11:10:04,839] INFO - prefect.FlowRunner | Beginning Flow run for 'fit'\n",
      "[2019-08-29 11:10:04,841] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2019-08-29 11:10:04,848] INFO - prefect.TaskRunner | Task 'Constant[str]': Starting task run...\n",
      "[2019-08-29 11:10:04,850] INFO - prefect.TaskRunner | Task 'Constant[str]': finished task run for task with final state: 'Success'\n",
      "[2019-08-29 11:10:04,851] INFO - prefect.TaskRunner | Task 'ShellTask': Starting task run...\n",
      "[2019-08-29 11:10:05,321] INFO - prefect.TaskRunner | Task 'ShellTask': finished task run for task with final state: 'Success'\n",
      "[2019-08-29 11:10:05,325] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Success: \"All reference tasks succeeded.\">"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PxW\n",
    "\n",
    "# Check if the package gets installed correctly.\n",
    "clf = PxW.J48()\n",
    "\n",
    "clf.fit(fn_train, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-08-29 11:10:05,338] INFO - prefect.FlowRunner | Beginning Flow run for 'predict'\n",
      "[2019-08-29 11:10:05,339] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2019-08-29 11:10:05,343] INFO - prefect.TaskRunner | Task 'Constant[str]': Starting task run...\n",
      "[2019-08-29 11:10:05,344] INFO - prefect.TaskRunner | Task 'Constant[str]': finished task run for task with final state: 'Success'\n",
      "[2019-08-29 11:10:05,345] INFO - prefect.TaskRunner | Task 'ShellTask': Starting task run...\n",
      "[2019-08-29 11:10:05,579] INFO - prefect.TaskRunner | Task 'ShellTask': finished task run for task with final state: 'Success'\n",
      "[2019-08-29 11:10:05,580] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    }
   ],
   "source": [
    "out = clf.predict(fn_test, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cf. [this stackoverflow](https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn) to get some insights on encoding. Here it don't matter since I just want an F1 score anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_weka(out, average='macro'):\n",
    "    out = out.apply(LabelEncoder().fit_transform)\n",
    "    f1 = f1_score(out['actual'], out['predicted'], average=average)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9665831244778613"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_weka(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/step-02/iris-q_001.arff'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs\n",
    "fn_test = filename(dataset, step=1, suffix='test')\n",
    "\n",
    "q_idx = 1\n",
    "fn_qry = filename(dataset, step=2, suffix='q_{}'.format(str(q_idx).zfill(3)))\n",
    "fn_qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2   3                4\n",
      "0  4.4  3.0  1.3 NaN      Iris-setosa\n",
      "1  6.1  3.0  4.9 NaN   Iris-virginica\n",
      "2  4.9  2.4  3.3 NaN  Iris-versicolor\n",
      "3  5.0  2.3  3.3 NaN  Iris-versicolor\n",
      "4  4.4  3.2  1.3 NaN      Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "df_test, af_test = arff_to_df(fn_test, encode_nominal=False, return_af=True)\n",
    "\n",
    "#df_test.iloc[:, 0] = np.nan\n",
    "#df_test.iloc[:, 1] = np.nan\n",
    "#df_test.iloc[:, 2] = np.nan\n",
    "df_test.iloc[:, 3] = np.nan\n",
    "\n",
    "print(df_test.head()) \n",
    "\n",
    "af_qry = af_test.copy()\n",
    "af_qry['data'] = df_test.values\n",
    "\n",
    "with open(fn_qry, 'w') as f:\n",
    "    arff.dump(af_qry, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-08-29 11:10:05,679] INFO - prefect.FlowRunner | Beginning Flow run for 'fit'\n",
      "[2019-08-29 11:10:05,681] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2019-08-29 11:10:05,687] INFO - prefect.TaskRunner | Task 'Constant[str]': Starting task run...\n",
      "[2019-08-29 11:10:05,688] INFO - prefect.TaskRunner | Task 'Constant[str]': finished task run for task with final state: 'Success'\n",
      "[2019-08-29 11:10:05,690] INFO - prefect.TaskRunner | Task 'ShellTask': Starting task run...\n",
      "[2019-08-29 11:10:06,140] INFO - prefect.TaskRunner | Task 'ShellTask': finished task run for task with final state: 'Success'\n",
      "[2019-08-29 11:10:06,142] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n",
      "[2019-08-29 11:10:06,145] INFO - prefect.FlowRunner | Beginning Flow run for 'predict'\n",
      "[2019-08-29 11:10:06,147] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2019-08-29 11:10:06,153] INFO - prefect.TaskRunner | Task 'Constant[str]': Starting task run...\n",
      "[2019-08-29 11:10:06,154] INFO - prefect.TaskRunner | Task 'Constant[str]': finished task run for task with final state: 'Success'\n",
      "[2019-08-29 11:10:06,156] INFO - prefect.TaskRunner | Task 'ShellTask': Starting task run...\n",
      "[2019-08-29 11:10:06,391] INFO - prefect.TaskRunner | Task 'ShellTask': finished task run for task with final state: 'Success'\n",
      "[2019-08-29 11:10:06,393] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n",
      "/home/zissou/miniconda3/envs/aaai20/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2501414827391058"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if it works\n",
    "clf = PxW.J48()\n",
    "clf.fit(fn_train, verbose=False)\n",
    "out = clf.predict(fn_qry, verbose=True)\n",
    "\n",
    "f1_weka(out, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Query File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_contents(list_one, list_two, nb_items_to_transfer=1):\n",
    "    list_one, list_two = list_one.copy(), list_two.copy() \n",
    "    \n",
    "    idx_to_transfer = np.random.choice(range(len(list_one)), nb_items_to_transfer, replace=False)\n",
    "    content_to_transfer = [e for idx, e in enumerate(list_one) if idx in idx_to_transfer]\n",
    "    \n",
    "    for e in content_to_transfer:\n",
    "        list_one.remove(e)\n",
    "        list_two.append(e)\n",
    "    \n",
    "    return list_one, list_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qry(nb_atts, targ_idx=-1, nb_qry=10):\n",
    "    # init ids\n",
    "    attr_ids = list(range(nb_atts))\n",
    "    targ_ids = [attr_ids[targ_idx]] # Last attribute by default\n",
    "    desc_ids = [e for e in attr_ids if e not in targ_ids]\n",
    "    miss_ids = []\n",
    "\n",
    "    q_targ = [targ_ids]\n",
    "    q_desc = [desc_ids]\n",
    "    q_miss = [miss_ids]\n",
    "\n",
    "    # Start query buiding\n",
    "    nb_of_attributes_to_make_missing = np.linspace(0, nb_atts-1, nb_qry, endpoint=False, dtype=int)\n",
    "    nb_items_to_transfer = np.ediff1d(nb_of_attributes_to_make_missing)\n",
    "\n",
    "    for qry_id, e in enumerate(nb_items_to_transfer):\n",
    "        desc_ids, miss_ids = transfer_contents(desc_ids, miss_ids, nb_items_to_transfer=e)\n",
    "\n",
    "        #print(desc_ids, miss_ids, targ_ids)\n",
    "        q_targ.append(targ_ids)\n",
    "        q_desc.append(desc_ids)\n",
    "        q_miss.append(miss_ids)\n",
    "    \n",
    "    return q_desc, q_targ, q_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modulo.utils.encoding import query_to_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_queries(filename, queries):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Queries Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "fn_test = filename(dataset, step=1, suffix='test')\n",
    "\n",
    "# Queries\n",
    "df_test, af_test = arff_to_df(fn_test, encode_nominal=False, return_af=True)\n",
    "nb_atts = len(df_test.columns)\n",
    "nb_qry = 4\n",
    "\n",
    "q_desc, q_targ, q_miss = generate_qry(nb_atts, targ_idx=-1, nb_qry=nb_qry)\n",
    "\n",
    "q_codes = []\n",
    "\n",
    "for q_idx, miss_ids in enumerate(q_miss):\n",
    "    q_codes.append(query_to_code(q_desc[q_idx], q_targ[q_idx], q_miss[q_idx]))\n",
    "    \n",
    "    df_qry = df_test.copy()\n",
    "    af_qry = af_test.copy()\n",
    "    fn_qry = filename(dataset, step=2, suffix='q_{}'.format(str(q_idx).zfill(3)))\n",
    "    \n",
    "    df_qry.iloc[:, miss_ids] = np.nan\n",
    "    af_qry['data'] = df_qry.values\n",
    "\n",
    "    with open(fn_qry, 'w') as f:\n",
    "        arff.dump(af_qry, f)\n",
    "        \n",
    "q_codes = np.r_[q_codes] # Convert to proper np.ndarray\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  1],\n",
       "       [-1,  0,  0,  0,  1],\n",
       "       [-1,  0, -1,  0,  1],\n",
       "       [-1,  0, -1, -1,  1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.r_[q_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_desc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-f1118c84cf20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/zissou/miniconda3/envs/aaai20/lib/python3.6/site-packages/numpy/lib/index_tricks.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "np.c_[None, a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0, -1, -1,  1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_idx = 3\n",
    "query_to_code(q_desc[q_idx], q_targ[q_idx], q_miss[q_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/step-02/iris-q_001.arff'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_idx = 1\n",
    "fn_qry = filename(dataset, step=2, suffix='q_{}'.format(str(q_idx).zfill(3)))\n",
    "fn_qry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaai20-belafonte",
   "language": "python",
   "name": "aaai20-belafonte"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
