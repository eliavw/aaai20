{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modulo Exp Def\n",
    "\n",
    "Final notebook which conducts the Modulo experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arff\n",
    "import os\n",
    "import numpy as np\n",
    "import aaai20\n",
    "import PxW\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor, XGBRFRegressor\n",
    "\n",
    "from os.path import dirname\n",
    "from aaai20.io import filename_dataset, filename_query\n",
    "from aaai20.exp import collect_results\n",
    "from aaai20.wrangling import arff_to_df\n",
    "from aaai20.exp import collect_results, process_outcomes, save_outcome\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mercs.core import Mercs as Modulo\n",
    "from mercs.utils.encoding import query_to_code, code_to_query, encode_attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_to_ok_df(filename, encode=True):\n",
    "    \"\"\"\n",
    "    Convenience function. Preprocess so its ready for sklearn.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = arff_to_df(filename, return_af=False, encode_nominal=False)\n",
    "    qry = qry_from_df(df)\n",
    "    \n",
    "    if encode:\n",
    "        df_nominal = df.select_dtypes(exclude=['float'])\n",
    "        \n",
    "        label_encoders = {}\n",
    "        for c in df_nominal.columns:\n",
    "            label_encoders[c] = LabelEncoder()\n",
    "            label_encoders[c].fit(df_nominal[c])\n",
    "            df_nominal[c] = label_encoders[c].transform(df_nominal[c])\n",
    "\n",
    "        df[df_nominal.columns] = df_nominal.copy()    \n",
    "        nominal = df_nominal.columns.values\n",
    "\n",
    "        return df, qry, nominal, label_encoders\n",
    "    else:\n",
    "        return df, qry\n",
    "    \n",
    "def qry_from_df(df):\n",
    "    qry = np.zeros(len(df.columns), dtype=int)\n",
    "    \n",
    "    miss_ids = df.columns[df.isna().any()].tolist()\n",
    "    targ_ids = df.columns[-1]\n",
    "    \n",
    "    qry[miss_ids] = -1\n",
    "    qry[targ_ids] = 1\n",
    "    return qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_nominal(df):\n",
    "    df_nominal = df.select_dtypes(exclude=['float'])\n",
    "    \n",
    "    nominal = [idx for idx, c in enumerate(df) if c in df_nominal.columns]\n",
    "    \n",
    "    return nominal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_modulo(\n",
    "    dataset,\n",
    "    target_idx=-1,\n",
    "    random_state=42,\n",
    "    prediction_algorithm=\"mi\",\n",
    "    classifier_algorithm=\"DT\",\n",
    "    regressor_algorithm=\"DT\",\n",
    "    clf_criterion=\"gini\",\n",
    "    rgr_criterion=\"mse\",\n",
    "    selection_algorithm=\"base\",\n",
    "    nb_targets=1,\n",
    "    fraction_missing=0.2,\n",
    "    nb_iterations=1,\n",
    "    min_samples_leaf=2,\n",
    "    min_impurity_decrease=0.0,\n",
    "    max_steps=8,\n",
    "    max_depth=None,\n",
    "):\n",
    "\n",
    "    # Preliminaries\n",
    "    fn_train = filename_dataset(dataset, step=1, suffix=\"train\", extension=\"csv\")\n",
    "    df = pd.read_csv(fn_train, header=None, index_col=None)\n",
    "    train = df.values\n",
    "\n",
    "    nominal = detect_nominal(df)\n",
    "\n",
    "    msg = \"\"\"\n",
    "    Nominal attributes detected in dataset: {}\n",
    "    Nominal: {}\n",
    "    \"\"\".format(\n",
    "        dataset, nominal\n",
    "    )\n",
    "    # print(msg)\n",
    "\n",
    "    target_id = list(range(df.shape[1]))[\n",
    "        target_idx\n",
    "    ]  # Assumption: Last attribute is target\n",
    "    nominal_ids = set(list(nominal) + [target_id])\n",
    "    # print(nominal_ids)\n",
    "\n",
    "    # Train\n",
    "    clf = Modulo(\n",
    "        random_state=random_state,\n",
    "        nb_targets=nb_targets,\n",
    "        classifier_algorithm=classifier_algorithm,\n",
    "        regressor_algorithm=regressor_algorithm,\n",
    "        prediction_algorithm=prediction_algorithm,\n",
    "        clf_criterion=clf_criterion,\n",
    "        rgr_criterion=rgr_criterion,\n",
    "        selection_algorithm=selection_algorithm,\n",
    "        fraction_missing=fraction_missing,\n",
    "        nb_iterations=nb_iterations,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        min_impurity_decrease=min_impurity_decrease,\n",
    "        max_depth=max_depth,\n",
    "        max_steps=max_steps,\n",
    "    )\n",
    "\n",
    "    clf.fit(train, nominal_attributes=nominal_ids)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_modulo(dataset, classifier, target_idx=-1, prediction_algorithm=None, **prediction_kwargs):\n",
    "    result = []\n",
    "    \n",
    "    # Load queries\n",
    "    fn_qry = filename_query(dataset, suffix=\"default\")\n",
    "    q_codes = np.load(fn_qry)\n",
    "    q_codes_return = q_codes.copy()\n",
    "    \n",
    "    for q_idx, q_code in enumerate(q_codes):\n",
    "        fn = filename_dataset(dataset, step=2, suffix='q_{}'.format(str(q_idx).zfill(3)), extension='csv')\n",
    "        df_qry = pd.read_csv(fn, header=None, index_col=None)\n",
    "        \n",
    "        #print(df_qry.head())\n",
    "        q_code_2 = qry_from_df(df_qry)\n",
    "\n",
    "        target_id = list(range(df_qry.shape[1]))[target_idx] # Assumption: Last\n",
    "        \n",
    "        msg = \"\"\"\n",
    "        q_code from file: {}\n",
    "        q_code from data: {}\n",
    "        \"\"\".format(q_code, q_code_2)\n",
    "        #print(msg)\n",
    "        \n",
    "        assert(np.array_equal(q_code, q_code_2))\n",
    "        \n",
    "        test = df_qry.values\n",
    "        y_true = test[:,target_id].copy()\n",
    "        #y_true = y_true.astype(int)\n",
    "        test[:, target_id] = np.nan\n",
    "        \n",
    "        if prediction_algorithm is None:\n",
    "            y_pred = classifier.predict(test, q_code=q_code)\n",
    "        else:\n",
    "            y_pred = classifier.predict(test, q_code=q_code, prediction_algorithm=prediction_algorithm, **prediction_kwargs)\n",
    "        \n",
    "        #y_pred = y_pred.astype(int).ravel()\n",
    "        f1 = f1_score(y_true, y_pred, average='micro')\n",
    "        result.append(f1)\n",
    "        \n",
    "    return q_codes_return, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(ds):\n",
    "    clf = fit_modulo(ds,\n",
    "                     target_idx=-1,\n",
    "                     random_state=RANDOM_STATE,\n",
    "                     classifier_algorithm=\"DT\",\n",
    "                     regressor_algorithm=\"DT\",\n",
    "                     nb_targets=2,\n",
    "                     #clf_criterion=\"gini\",\n",
    "                     #rgr_criterion=\"friedman_mse\",\n",
    "                     selection_algorithm=\"random\",\n",
    "                     nb_iterations=ITERATIONS,\n",
    "                     fraction_missing=FRACTION_MISSING,\n",
    "                     #min_samples_leaf=MIN_SAMPLES_LEAF,\n",
    "                     max_depth=MAX_DEPTH,\n",
    "                     )\n",
    "\n",
    "    q_codes, results = predict_modulo(ds, clf, prediction_algorithm='mi')\n",
    "    mi = collect_results(ds, q_codes, results, algorithm='sklearn')\n",
    "    print(\"mi done\")\n",
    "\n",
    "    q_codes, results = predict_modulo(ds, clf, prediction_algorithm='mrai',)\n",
    "    mrai = collect_results(ds, q_codes, results, algorithm='mrai-new')\n",
    "    print(\"mrai done\")\n",
    "\n",
    "    q_codes, results = predict_modulo(ds, clf, prediction_algorithm='it', max_steps=8)\n",
    "    it = collect_results(ds, q_codes, results, algorithm='it-new')\n",
    "    print(\"it done\")\n",
    "    \n",
    "    q_codes, results = predict_modulo(ds, clf, prediction_algorithm='rw', max_steps=8, nb_walks=16)\n",
    "    rw = collect_results(ds, q_codes, results, algorithm='rw-new')\n",
    "    print(\"rw done\")\n",
    "    return mi, mrai, it, rw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "FRACTION_MISSING = [0, 0.3]\n",
    "ITERATIONS = 1\n",
    "MAX_DEPTH = 12\n",
    "MIN_SAMPLES_LEAF = 10\n",
    "\n",
    "datasets = ['glass',\n",
    "             'credit-g',\n",
    "             'ionosphere',\n",
    "             'lymph',\n",
    "             'vehicle',\n",
    "             'iris',\n",
    "             'splice',\n",
    "             'sonar',\n",
    "             'vowel',\n",
    "             'segment',\n",
    "             'zoo',\n",
    "             'heart-statlog',\n",
    "             'waveform-5000',\n",
    "             'kr-vs-kp',\n",
    "             'diabetes',\n",
    "             'letter',\n",
    "             'balance-scale']\n",
    "\n",
    "print(len(datasets))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfs = []\n",
    "for ds in datasets[:1]:\n",
    "    print(ds)\n",
    "    dfs.append(run_experiment(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "\n            Topological sort failed, investigate diagram to debug.\n            \n            I will never be able to squeeze a prediction out of a diagram with a loop.\n            \n            Cycle was:  [('f-04', 'd-04', 'forward'), ('d-04', 'f-03', 'forward'), ('f-03', 'd-07', 'forward'), ('d-07', 'f-04', 'forward')]\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/cw/dtailocal/repos/mercs/src/mercs/core/Mercs.py\", line 258, in _get_q_model\n    self.inference_algorithm(q_diagram, X=X)\n  File \"/cw/dtailocal/repos/mercs/src/mercs/algo/inference.py\", line 109, in dask_inference_algorithm\n    sorted_nodes = list(nx.topological_sort(g))\n  File \"/home/elia/miniconda3/envs/aaai20/lib/python3.6/site-packages/networkx/algorithms/dag.py\", line 208, in topological_sort\n    raise nx.NetworkXUnfeasible(\"Graph contains a cycle or graph changed \"\nnetworkx.exception.NetworkXUnfeasible: Graph contains a cycle or graph changed during iteration\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/elia/miniconda3/envs/aaai20/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/home/elia/miniconda3/envs/aaai20/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/elia/miniconda3/envs/aaai20/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/elia/miniconda3/envs/aaai20/lib/python3.6/site-packages/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/elia/miniconda3/envs/aaai20/lib/python3.6/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"<ipython-input-7-cd00d0c302c2>\", line 29, in run_experiment\n  File \"<ipython-input-6-d2ae8ff44850>\", line 34, in predict_modulo\n  File \"/cw/dtailocal/repos/mercs/src/mercs/core/Mercs.py\", line 206, in predict\n    self.q_models = [self._get_q_model(d, X) for d in self.q_diagram]\n  File \"/cw/dtailocal/repos/mercs/src/mercs/core/Mercs.py\", line 206, in <listcomp>\n    self.q_models = [self._get_q_model(d, X) for d in self.q_diagram]\n  File \"/cw/dtailocal/repos/mercs/src/mercs/core/Mercs.py\", line 270, in _get_q_model\n    raise RecursionError(msg)\nRecursionError: \n            Topological sort failed, investigate diagram to debug.\n            \n            I will never be able to squeeze a prediction out of a diagram with a loop.\n            \n            Cycle was:  [('f-04', 'd-04', 'forward'), ('d-04', 'f-03', 'forward'), ('f-03', 'd-07', 'forward'), ('d-07', 'f-04', 'forward')]\n            \n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-12ce93a9d97b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/elia/miniconda3/envs/aaai20/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elia/miniconda3/envs/aaai20/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elia/miniconda3/envs/aaai20/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elia/miniconda3/envs/aaai20/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elia/miniconda3/envs/aaai20/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: \n            Topological sort failed, investigate diagram to debug.\n            \n            I will never be able to squeeze a prediction out of a diagram with a loop.\n            \n            Cycle was:  [('f-04', 'd-04', 'forward'), ('d-04', 'f-03', 'forward'), ('f-03', 'd-07', 'forward'), ('d-07', 'f-04', 'forward')]\n            "
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "dfs =  Parallel(n_jobs=7)(delayed(run_experiment)(ds) for ds in datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_01 = {k:[] for k in datasets}\n",
    "dfs_02 = {k:[] for k in datasets}\n",
    "dfs_03 = {k:[] for k in datasets}\n",
    "dfs_04 = {k:[] for k in datasets}\n",
    "\n",
    "for (mi, mrai, it, rw), ds in zip(dfs, datasets):\n",
    "    dfs_01[ds] = mi\n",
    "    dfs_02[ds] = mrai\n",
    "    dfs_03[ds] = it\n",
    "    dfs_04[ds] = rw\n",
    "    \n",
    "for dfs, algo in zip((dfs_01, dfs_02, dfs_03, dfs_04), ('mi', 'mrai', 'it', 'rw')):\n",
    "    df = process_outcomes(dfs)\n",
    "    save_outcome(df, filename=algo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaai20-frost",
   "language": "python",
   "name": "aaai20-frost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
